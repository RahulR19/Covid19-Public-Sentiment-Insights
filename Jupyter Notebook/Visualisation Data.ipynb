{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center><h1> Data for Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the code for preparing the processed data for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS) #Set of English Stopwords\n",
    "\n",
    "import numpy as npy\n",
    "from PIL import Image\n",
    "\n",
    "maskArray = npy.array(Image.open(\"mask.png\")) # Twitter Logo as a mask for wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant files\n",
    "\n",
    "sent_df = pd.read_csv(\"Processed Data.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106147</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>#IndiaFightsCorona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97350</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>#Corona #CoronavirusOutbreakindia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541724</th>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>#ThankYouHeroes #Toys #Kids #MommyBabyTimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528252</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>#GlobalGradShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100381</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>#GlobalCeasefire #Covid19Pandemic #Coronavirus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                        hashtags\n",
       "106147  2020-04-03                              #IndiaFightsCorona\n",
       "97350   2020-04-02               #Corona #CoronavirusOutbreakindia\n",
       "541724  2020-06-12     #ThankYouHeroes #Toys #Kids #MommyBabyTimes\n",
       "528252  2020-06-11                                 #GlobalGradShow\n",
       "100381  2020-04-03  #GlobalCeasefire #Covid19Pandemic #Coronavirus"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "hash_df = sent_df.loc[:,['date','hashtags']]\n",
    "hash_df = hash_df[pd.notna(hash_df['hashtags'])]\n",
    "hash_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into different lockdown phases, find the top 10 hashtags and save the data\n",
    "\n",
    "lockdown1 = hash_df[(hash_df['date'] >= '2020-03-25') & (hash_df['date'] <= '2020-04-14')]\n",
    "lockdown1 = pd.DataFrame(lockdown1['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown1.reset_index(inplace=True)\n",
    "lockdown1.insert(0, \"Phase\", \"LD1\")\n",
    "lockdown1.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown2 = hash_df[(hash_df['date'] >= '2020-04-15') & (hash_df['date'] <= '2020-05-03')]\n",
    "lockdown2 = pd.DataFrame(lockdown2['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown2.reset_index(inplace=True)\n",
    "lockdown2.insert(0, \"Phase\", \"LD2\")\n",
    "lockdown2.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown3 = hash_df[(hash_df['date'] >= '2020-05-04') & (hash_df['date'] <= '2020-05-17')]\n",
    "lockdown3 = pd.DataFrame(lockdown3['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown3.reset_index(inplace=True)\n",
    "lockdown3.insert(0, \"Phase\", \"LD3\")\n",
    "lockdown3.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "lockdown4 = hash_df[(hash_df['date'] >= '2020-05-18') & (hash_df['date'] <= '2020-05-31')]\n",
    "lockdown4 = pd.DataFrame(lockdown4['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "lockdown4.reset_index(inplace=True)\n",
    "lockdown4.insert(0, \"Phase\", \"LD4\")\n",
    "lockdown4.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "unlock1 = hash_df[(hash_df['date'] >= '2020-06-01') & (hash_df['date'] <= '2020-06-14')]\n",
    "unlock1 = pd.DataFrame(unlock1['hashtags'].str.split(expand=True).stack().value_counts()).head(10)\n",
    "unlock1.reset_index(inplace=True)\n",
    "unlock1.insert(0, \"Phase\", \"Unlock1\")\n",
    "unlock1.rename({0:\"value\",\"index\":\"hashtag\"},axis=1,inplace=True)\n",
    "\n",
    "combined_df = pd.concat([lockdown1,lockdown2,lockdown3,lockdown4,unlock1],ignore_index=True)\n",
    "combined_df.to_csv(\"Hashtag data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>username</th>\n",
       "      <th>to</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508701</th>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>15:35:48</td>\n",
       "      <td>AnshGup10217390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@PMOIndia @myogioffice @nitin_gadkari Dear sir...</td>\n",
       "      <td>@PMOIndia @myogioffice @nitin_gadkari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1269654299409289216</td>\n",
       "      <td>https://twitter.com/AnshGup10217390/status/126...</td>\n",
       "      <td>USER_MENTION USER_MENTION USER_MENTION dear si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481326</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>10:24:02</td>\n",
       "      <td>jay_arrah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Two educational institutions have become pione...</td>\n",
       "      <td>@achyuta_samanta @KIITUniversity @kissfoundation</td>\n",
       "      <td>#KIITKISSFightsCovid19</td>\n",
       "      <td>1267039125829382144</td>\n",
       "      <td>https://twitter.com/jay_arrah/status/126703912...</td>\n",
       "      <td>two educational institution become pioneer con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443442</th>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>12:35:07</td>\n",
       "      <td>danizaydi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>DANI’S CORONA RAYA COMING THIS EID 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1263810621604163584</td>\n",
       "      <td>https://twitter.com/danizaydi/status/126381062...</td>\n",
       "      <td>corona raya coming eid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      time         username   to  replies  retweets  \\\n",
       "508701  2020-06-07  15:35:48  AnshGup10217390  NaN        0         0   \n",
       "481326  2020-05-31  10:24:02        jay_arrah  NaN        0         1   \n",
       "443442  2020-05-22  12:35:07        danizaydi  NaN        2        12   \n",
       "\n",
       "        favorites                                               text  \\\n",
       "508701          1  @PMOIndia @myogioffice @nitin_gadkari Dear sir...   \n",
       "481326          3  Two educational institutions have become pione...   \n",
       "443442         29           DANI’S CORONA RAYA COMING THIS EID 2020    \n",
       "\n",
       "                                                mentions  \\\n",
       "508701             @PMOIndia @myogioffice @nitin_gadkari   \n",
       "481326  @achyuta_samanta @KIITUniversity @kissfoundation   \n",
       "443442                                               NaN   \n",
       "\n",
       "                      hashtags                   id  \\\n",
       "508701                     NaN  1269654299409289216   \n",
       "481326  #KIITKISSFightsCovid19  1267039125829382144   \n",
       "443442                     NaN  1263810621604163584   \n",
       "\n",
       "                                                permalink  \\\n",
       "508701  https://twitter.com/AnshGup10217390/status/126...   \n",
       "481326  https://twitter.com/jay_arrah/status/126703912...   \n",
       "443442  https://twitter.com/danizaydi/status/126381062...   \n",
       "\n",
       "                                           processed_text  \n",
       "508701  USER_MENTION USER_MENTION USER_MENTION dear si...  \n",
       "481326  two educational institution become pioneer con...  \n",
       "443442                             corona raya coming eid  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "\n",
    "df = pd.read_csv(\"Processed Data.csv\",sep='\\t')\n",
    "df['processed_text']=df['processed_text'].astype(str)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>yeah missing freedom life covid19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>contribute cm relief fund help delhi govt figh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>bhai assalamualaikum possible please call bhai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>bold adress nation activity banned except esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>please understand important stay home responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582685</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582686</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582687</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>italy face two new coronavirus outbreak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582688</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>india become top none modi reign india became ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582689</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>tokyo report jump coronavirus case many linked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                                     processed_text\n",
       "0       2020-03-25                  yeah missing freedom life covid19\n",
       "1       2020-03-25  contribute cm relief fund help delhi govt figh...\n",
       "2       2020-03-25  bhai assalamualaikum possible please call bhai...\n",
       "3       2020-03-25  bold adress nation activity banned except esse...\n",
       "4       2020-03-25  please understand important stay home responsi...\n",
       "...            ...                                                ...\n",
       "582685  2020-06-14                                                URL\n",
       "582686  2020-06-14                                              covid\n",
       "582687  2020-06-14            italy face two new coronavirus outbreak\n",
       "582688  2020-06-14  india become top none modi reign india became ...\n",
       "582689  2020-06-14  tokyo report jump coronavirus case many linked...\n",
       "\n",
       "[582690 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary data\n",
    "\n",
    "cloud_df = df.loc[:,['date','processed_text']]\n",
    "cloud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise WordCloud\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"USER_MENTION\",\"URL\"])  #To add any custom StopWords\n",
    "wordcloud = WordCloud(background_color = \"#97CAEF\",stopwords = stopwords, collocations=False, mask = maskArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x1d8b7991f10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into different lockdown phases, generate wordcloud and save the data\n",
    "\n",
    "lockdown1 = cloud_df[(cloud_df['date'] >= '2020-03-25') & (cloud_df['date'] <= '2020-04-14')]\n",
    "text = []\n",
    "for item in lockdown1['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown1text = \" \".join(string)\n",
    "wordcloud.generate(lockdown1text)\n",
    "wordcloud.to_file(\"Lockdown1 cloud.png\")\n",
    "\n",
    "lockdown2 = cloud_df[(cloud_df['date'] >= '2020-04-15') & (cloud_df['date'] <= '2020-05-03')]\n",
    "text = []\n",
    "for item in lockdown2['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown2text = \" \".join(string)\n",
    "wordcloud.generate(lockdown2text)\n",
    "wordcloud.to_file(\"Lockdown2 cloud.png\")\n",
    "\n",
    "lockdown3 = cloud_df[(cloud_df['date'] >= '2020-05-04') & (cloud_df['date'] <= '2020-05-17')]\n",
    "text = []\n",
    "for item in lockdown3['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown3text = \" \".join(string)\n",
    "wordcloud.generate(lockdown3text)\n",
    "wordcloud.to_file(\"Lockdown3 cloud.png\")\n",
    "\n",
    "lockdown4 = cloud_df[(cloud_df['date'] >= '2020-05-18') & (cloud_df['date'] <= '2020-05-31')]\n",
    "text = []\n",
    "for item in lockdown4['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "lockdown4text = \" \".join(string)\n",
    "wordcloud.generate(lockdown4text)\n",
    "wordcloud.to_file(\"Lockdown4 cloud.png\")\n",
    "\n",
    "unlock1 = cloud_df[(cloud_df['date'] >= '2020-06-01') & (cloud_df['date'] <= '2020-06-14')]\n",
    "text = []\n",
    "for item in unlock1['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "unlock1text = \" \".join(string)\n",
    "wordcloud.generate(unlock1text)\n",
    "wordcloud.to_file(\"Unlock1 cloud.png\")\n",
    "\n",
    "\n",
    "#General Data\n",
    "text = []\n",
    "for item in cloud_df['processed_text']:\n",
    "    text.append(str(data) for data in item)\n",
    "string = [\"\".join(data) for data in text]\n",
    "generaltext = \" \".join(string)\n",
    "wordcloud.generate(generaltext)\n",
    "wordcloud.to_file(\"General cloud.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
